{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d28ae9d6-cd37-485a-b022-c347f319c260",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c38d578e-ca94-40b8-9341-79f4287316f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mLoading .env environment variables...\u001b[0m\n",
      "\u001b[1;32mInstalling langchain_community...\u001b[0m\n",
      "✔ Installation Succeeded\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1;39m(f6673e)...\u001b[0m\n",
      "\u001b[32mAll dependencies are now up-to-date!\u001b[0m\n",
      "\u001b[1;32mUpgrading\u001b[0m langchain_community in \u001b[39m dependencies.\u001b[0m\n",
      "\u001b[?25lBuilding requirements...\n",
      "\u001b[2KResolving dependencies....\n",
      "\u001b[2K✔ Success! Locking packages...\n",
      "\u001b[2K\u001b[32m⠙\u001b[0m Locking packages...\n",
      "\u001b[1A\u001b[2K\u001b[?25lBuilding requirements...\n",
      "\u001b[2KResolving dependencies....\n",
      "\u001b[2K✔ Success! Locking packages...\n",
      "\u001b[2K\u001b[32m⠇\u001b[0m Locking packages...\n",
      "\u001b[1A\u001b[2K\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1;39m(36fc99)...\u001b[0m\n",
      "\u001b[32mAll dependencies are now up-to-date!\u001b[0m\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1;39m(36fc99)...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pipenv install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaf65424-ced2-4ab6-a147-da3c75768445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.30.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /home/ujjwalks9/.local/share/virtualenvs/Cold_email_generator-YjcryWd-/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.29.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /home/ujjwalks9/.local/share/virtualenvs/Cold_email_generator-YjcryWd-/lib/python3.11/site-packages (from selenium) (2025.1.31)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /home/ujjwalks9/.local/share/virtualenvs/Cold_email_generator-YjcryWd-/lib/python3.11/site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /home/ujjwalks9/.local/share/virtualenvs/Cold_email_generator-YjcryWd-/lib/python3.11/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: requests in /home/ujjwalks9/.local/share/virtualenvs/Cold_email_generator-YjcryWd-/lib/python3.11/site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in /home/ujjwalks9/.local/share/virtualenvs/Cold_email_generator-YjcryWd-/lib/python3.11/site-packages (from webdriver-manager) (1.1.0)\n",
      "Requirement already satisfied: packaging in /home/ujjwalks9/.local/share/virtualenvs/Cold_email_generator-YjcryWd-/lib/python3.11/site-packages (from webdriver-manager) (24.2)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /home/ujjwalks9/.local/share/virtualenvs/Cold_email_generator-YjcryWd-/lib/python3.11/site-packages (from trio~=0.17->selenium) (25.3.0)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna in /home/ujjwalks9/.local/share/virtualenvs/Cold_email_generator-YjcryWd-/lib/python3.11/site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /home/ujjwalks9/.local/share/virtualenvs/Cold_email_generator-YjcryWd-/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ujjwalks9/.local/share/virtualenvs/Cold_email_generator-YjcryWd-/lib/python3.11/site-packages (from requests->webdriver-manager) (3.4.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /home/ujjwalks9/.local/share/virtualenvs/Cold_email_generator-YjcryWd-/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Downloading selenium-4.30.0-py3-none-any.whl (9.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Downloading trio-0.29.0-py3-none-any.whl (492 kB)\n",
      "Downloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Installing collected packages: sortedcontainers, wsproto, pysocks, outcome, webdriver-manager, trio, trio-websocket, selenium\n",
      "Successfully installed outcome-1.3.0.post0 pysocks-1.7.1 selenium-4.30.0 sortedcontainers-2.4.0 trio-0.29.0 trio-websocket-0.12.2 webdriver-manager-4.0.2 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium webdriver-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0674f2a6-9a67-4c86-8b82-7bbcc15a37f8",
   "metadata": {},
   "source": [
    "## Extract the job role, job skill in JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ff56cc5-cd43-4cc3-bcdc-40c5ff8386bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Python Developer - Analyst', 'description': 'You are a strategic thinker passionate about driving solutions using “Data”. You have found the right team.\\nAs a Data Engineer in our STO team, you will be a strategic thinker passionate about promoting solutions using data. You will mine, interpret, and clean our data, asking questions, connecting the dots, and uncovering hidden opportunities for realizing the data’s full potential. As part of a team of specialists, you will “slice and dice” data using various methods and create new visions for the future. Our STO team is focused on collaborating and partnering with business to deliver efficiency and enhance controls via technology adoption and infrastructure support for Global Finance & Business Management India.\\nJob Responsibilities\\nWrite efficient Python and SQL code to extract, transform, and load (ETL) data from various sources into Databricks.\\nPerform data analysis and computation to derive actionable insights from the data.\\nCollaborate with data scientists, analysts, and other stakeholders to understand data requirements and deliver solutions.\\nEnsure data quality, integrity, and security across all data processes.\\nDevelop Optimized solutions for performance and scalability.\\nMonitor and troubleshoot data workflows to ensure reliability and efficiency.\\nDocument data engineering processes, methodologies, and workflows. \\nCommunicating analytical findings to senior leaders through data visualization and storytelling\\n Required qualifications, capabilities and skills\\nMinimum 3 years of Develop, implement, and maintain data pipelines in Databricks to support data integration and analytics.\\nDevelop, implement, and maintain data pipelines in Databricks to support data integration and analytics.\\nWrite efficient Python and SQL code to extract, transform, and load (ETL) data from various sources into Databricks.\\nAbility to use LLM to build AI solutions.\\nPerform data analysis and computation to derive actionable insights from the data.\\nCollaborate with data scientists, analysts, and other stakeholders to understand data requirements and deliver solutions.\\nEnsure data quality, integrity, and security across all data processes.\\nOptimize data pipelines for performance and scalability.\\nMonitor and troubleshoot data workflows to ensure reliability and efficiency.\\nDocument data engineering processes, methodologies, and workflows.\\n Preferred qualifications, capabilities and skills\\nCertification in Databricks preferred.\\nExperience with cloud platforms (e.g., AWS, Azure, GCP) and their data services.\\nKnowledge of machine learning and data science concepts.\\nExperience with data visualization tool Tableau will be plus\\n '}\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "def extract_job_info(url):\n",
    "    \n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")  \n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    \n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    driver.get(url)\n",
    "    time.sleep(3)  \n",
    "\n",
    "    try:\n",
    "        job_title = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"h1\"))\n",
    "        ).text\n",
    "\n",
    "\n",
    "        job_desc = None\n",
    "        possible_selectors = [\n",
    "            \".job-description\",  \n",
    "            \"div[data-automation-id='jobDescription']\",  \n",
    "            \"div[class*='description']\" \n",
    "        ]\n",
    "\n",
    "        for selector in possible_selectors:\n",
    "            try:\n",
    "                job_desc = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, selector))\n",
    "                ).text\n",
    "                if job_desc:\n",
    "                    break  \n",
    "            except:\n",
    "                continue  \n",
    "        \n",
    "        if not job_desc:\n",
    "            job_desc = \"Job description not found\"\n",
    "\n",
    "        job_info = {\"title\": job_title, \"description\": job_desc}\n",
    "\n",
    "    except Exception as e:\n",
    "        job_info = {\"error\": f\"Failed to extract job details: {str(e)}\"}\n",
    "\n",
    "    driver.quit()\n",
    "    return job_info\n",
    "\n",
    "\n",
    "url = \"https://jpmc.fa.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1001/job/210606405?keyword=Python+Developer+-+Analyst&mode=location\"\n",
    "job_data = extract_job_info(url)\n",
    "print(job_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e132fc-8dbe-4cc5-9e92-95cacc23c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    api_key=\"YOUR_GROQ_API_KEY\",  # Add your actual Groq API key\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26f98961-7c6a-4776-9610-9ae2132f128a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "{\n",
      "  \"role\": \"Python Developer - Analyst\",\n",
      "  \"experience\": \"Minimum 3 years of experience in data engineering\",\n",
      "  \"skills\": [\n",
      "    \"Python\",\n",
      "    \"SQL\",\n",
      "    \"Databricks\",\n",
      "    \"Data analysis and computation\",\n",
      "    \"Data visualization\",\n",
      "    \"Tableau\",\n",
      "    \"Machine learning\",\n",
      "    \"Data science\",\n",
      "    \"Cloud platforms (AWS, Azure, GCP)\",\n",
      "    \"LLM (Large Language Model)\",\n",
      "    \"Data quality, integrity, and security\"\n",
      "  ],\n",
      "  \"description\": \"As a Data Engineer in our STO team, you will mine, interpret, and clean our data, asking questions, connecting the dots, and uncovering hidden opportunities for realizing the data’s full potential. You will write efficient Python and SQL code to extract, transform, and load (ETL) data from various sources into Databricks, perform data analysis and computation to derive actionable insights from the data, and collaborate with data scientists, analysts, and other stakeholders to understand data requirements and deliver solutions.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_extract = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    I will give you scraped text from the job posting. \n",
    "    Your job is to extract the job details & requirements in a JSON format containing the following keys: 'role', 'experience', 'skills', and 'description'. \n",
    "    Only return valid JSON. No preamble, please.\n",
    "    Here is the scraped text: {job_data}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain_extract = prompt_extract | llm \n",
    "response = chain_extract.invoke(input={'job_data':job_data})\n",
    "print(type(response.content))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7556aa7-9959-49ba-acad-da5ef0f9ee19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'role': 'Python Developer - Analyst', 'experience': 'Minimum 3 years of experience in data engineering', 'skills': ['Python', 'SQL', 'Databricks', 'Data analysis and computation', 'Data visualization', 'Tableau', 'Machine learning', 'Data science', 'Cloud platforms (AWS, Azure, GCP)', 'LLM (Large Language Model)', 'Data quality, integrity, and security'], 'description': 'As a Data Engineer in our STO team, you will mine, interpret, and clean our data, asking questions, connecting the dots, and uncovering hidden opportunities for realizing the data’s full potential. You will write efficient Python and SQL code to extract, transform, and load (ETL) data from various sources into Databricks, perform data analysis and computation to derive actionable insights from the data, and collaborate with data scientists, analysts, and other stakeholders to understand data requirements and deliver solutions.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "job_json= json_parser.parse(response.content)\n",
    "print(type(job_json))\n",
    "print(job_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee40a6c-0cf2-4ffb-b380-ad93a5dba3ca",
   "metadata": {},
   "source": [
    "## JSON format to ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ab9cc30-f1bc-46ca-b334-1bd38ec8b164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job details stored successfully in ChromaDB!\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "import uuid \n",
    "\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"./vectorstore\")\n",
    "\n",
    "\n",
    "collection = client.get_or_create_collection(name=\"job_portfolio\")\n",
    "\n",
    "\n",
    "job_details = {\n",
    "    \"skills\": [\n",
    "        \"Proficiency in Python programming\",\n",
    "        \"Experience with web frameworks such as Django or Flask\",\n",
    "        \"Understanding of multi-process architecture\",\n",
    "        \"Knowledge of front-end technologies like JavaScript, HTML5, and CSS3\",\n",
    "        \"Familiarity with event-driven programming\",\n",
    "        \"Strong problem-solving skills\",\n",
    "        \"Excellent communication and teamwork abilities\"\n",
    "    ],\n",
    "    \"experience\": [\n",
    "        \"Bachelor's degree in Computer Science, Engineering, or related field\",\n",
    "        \"2+ years of experience in Python development\",\n",
    "        \"Experience with version control systems like Git\",\n",
    "        \"Background in financial services or related industry is a plus\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "job_details_str = str(job_details)\n",
    "\n",
    "# Store job details in ChromaDB\n",
    "collection.add(\n",
    "    documents=[job_details_str],  \n",
    "    ids=[str(uuid.uuid4())],  \n",
    "    metadatas=[{\"source\": \"JPMorganChase\"}]  \n",
    ")\n",
    "\n",
    "print(\"Job details stored successfully in ChromaDB!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30a49e04-86f6-4408-98b7-227eaec1ef52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python',\n",
       " 'SQL',\n",
       " 'Databricks',\n",
       " 'Data analysis and computation',\n",
       " 'Data visualization',\n",
       " 'Tableau',\n",
       " 'Machine learning',\n",
       " 'Data science',\n",
       " 'Cloud platforms (AWS, Azure, GCP)',\n",
       " 'LLM (Large Language Model)',\n",
       " 'Data quality, integrity, and security']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response['skills']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28060d7-d244-4465-9471-ef3cdbdf2fd9",
   "metadata": {},
   "source": [
    "## Matches job skills to the closest portfolio in ChromaDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bf8065a-061c-4298-af2d-3093e38a0003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'match': ['{\\'skills\\': [\\'Proficiency in Python programming\\', \\'Experience with web frameworks such as Django or Flask\\', \\'Understanding of multi-process architecture\\', \\'Knowledge of front-end technologies like JavaScript, HTML5, and CSS3\\', \\'Familiarity with event-driven programming\\', \\'Strong problem-solving skills\\', \\'Excellent communication and teamwork abilities\\'], \\'experience\\': [\"Bachelor\\'s degree in Computer Science, Engineering, or related field\", \\'2+ years of experience in Python development\\', \\'Experience with version control systems like Git\\', \\'Background in financial services or related industry is a plus\\']}'], 'metadata': [{'source': 'JPMorganChase'}]}\n"
     ]
    }
   ],
   "source": [
    "def match_job_to_portfolio(job_json):\n",
    "\n",
    "    job_skills_str = str(job_json[\"skills\"])  \n",
    "\n",
    "    results = collection.query(\n",
    "        query_texts=[job_skills_str],\n",
    "        n_results=1  \n",
    "    )\n",
    "\n",
    "    if results[\"documents\"]:\n",
    "        return {\"match\": results[\"documents\"][0], \"metadata\": results[\"metadatas\"][0]}\n",
    "    else:\n",
    "        return {\"error\": \"No matching portfolio found\"}\n",
    "\n",
    "\n",
    "new_job = {\n",
    "    \"role\": job_json[\"role\"],\n",
    "    \"skills\": job_json[\"skills\"],\n",
    "    \"experience\": job_json[\"experience\"],\n",
    "    \"description\": job_json[\"description\"]\n",
    "}\n",
    "\n",
    "\n",
    "match_result = match_job_to_portfolio(new_job)\n",
    "print(match_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03a10f3-e184-4c7f-9424-494f02dce619",
   "metadata": {},
   "source": [
    "## Generates a cold email using extracted job details and the matched portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "102c026e-ba7b-4cf7-9922-16fc1896ffc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📩 Generated Cold Email:\n",
      "\n",
      "Here's a highly professional and persuasive cold email targeted at hiring managers or recruiters:\n",
      "\n",
      "Subject: Expert Python Developer for Python Developer - Analyst – Let’s Connect!\n",
      "\n",
      "Dear Hiring Manager,\n",
      "\n",
      "I came across the Python Developer - Analyst role at [Company Name] and was impressed by the opportunity to join a team that values data-driven insights. As a seasoned data engineer with a passion for unlocking the full potential of data, I believe my skills and experience make me an ideal fit for this position.\n",
      "\n",
      "With over 3 years of experience in data engineering, I possess a strong foundation in Python, SQL, and Databricks. My expertise in data analysis and computation, data visualization using Tableau, and machine learning has enabled me to deliver actionable insights to stakeholders in my previous roles. I'm also well-versed in cloud platforms (AWS, Azure, GCP) and have experience working with Large Language Models (LLM).\n",
      "\n",
      "One of my notable projects, which I believe aligns with your needs, is the \"Data Quality and Integrity\" project I led at JPMorganChase. In this project, I designed and implemented a data quality framework using Python and SQL, which resulted in a significant reduction in data errors and improved data integrity. I'd love to discuss how my experience can benefit your team.\n",
      "\n",
      "I'd appreciate the opportunity to discuss how I can contribute to [Company Name]'s success. Would love to discuss how we can add value to your team. Let’s schedule a quick call this week!\n",
      "\n",
      "Best regards,\n",
      "\n",
      "Ujjwal Kumar Singh\n",
      "ujjwalks2709@gmail.com\n",
      "+91 7543932088\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "def generate_cold_email(job_json, match_result):\n",
    "\n",
    "    job_role = job_json[\"role\"]\n",
    "    skills = \", \".join(job_json[\"skills\"])\n",
    "    experience = job_json[\"experience\"]\n",
    "    description = job_json[\"description\"]\n",
    "    \n",
    "    if \"match\" in match_result and \"metadata\" in match_result:\n",
    "        portfolio_source = match_result[\"metadata\"][0][\"source\"]\n",
    "    else:\n",
    "        portfolio_source = \"N/A\"\n",
    "\n",
    "    prompt_email = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        **Objective:**  \n",
    "        Craft a highly professional and persuasive cold email targeted at hiring managers or recruiters.  \n",
    "        The email should be personalized, highlighting how our company's experience, skills, and past projects align perfectly with the job role.  \n",
    "    \n",
    "        **Tone & Style:**  \n",
    "        - Professional, engaging, and confident  \n",
    "        - Concise and to the point (max 200 words)  \n",
    "        - Friendly but not overly casual  \n",
    "    \n",
    "        **Email Structure:**  \n",
    "    \n",
    "\n",
    "           - A compelling and personalized subject line that grabs attention.  \n",
    "           - Example: \"Expert Python Developer for {job_role} – Let’s Connect!\"  \n",
    "     \n",
    "           - Address the hiring manager or recruiter.  \n",
    "           - Mention the specific job role and company name.  \n",
    "           - Create a strong opening that sparks interest.  \n",
    "    \n",
    "           - Briefly mention relevant skills and experience based on the job posting.  \n",
    "           - Show how our past projects align with their needs.  \n",
    "           - Mention key technical skills that match the role.  \n",
    "      \n",
    "           - Highlight a relevant project from our portfolio.  \n",
    "           - Explain how our experience can benefit their team.  \n",
    "    \n",
    "           - Politely ask for a meeting or call.  \n",
    "           - Provide a direct way to contact us.  \n",
    "           - Example: \"Would love to discuss how we can add value to your team. Let’s schedule a quick call this week!\"  \n",
    "    \n",
    "        **Job Details:**  \n",
    "        - Role: {job_role}  \n",
    "        - Skills: {skills}  \n",
    "        - Experience: {experience}  \n",
    "        - Description: {description}  \n",
    "        - Matching Portfolio Source: {portfolio_source} \n",
    "\n",
    "        In saluatation don't mention hiring manager name, just give as Dear hiring manager.\n",
    "        You are Ujjwal Kumar Singh [name], your email is ujjwalks2709@gmail.com, your phone number is +91 7543932088.\n",
    "    \n",
    "        ✨ Ensure the email feels natural, avoids generic phrasing, and maximizes impact!  \n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "    chain_email = prompt_email | llm \n",
    "    response_email = chain_email.invoke(input={\n",
    "        \"job_role\": job_role,\n",
    "        \"skills\": skills,\n",
    "        \"experience\": experience,\n",
    "        \"description\": description,\n",
    "        \"portfolio_source\": portfolio_source\n",
    "    })\n",
    "\n",
    "    return response_email.content\n",
    "\n",
    "\n",
    "cold_email = generate_cold_email(new_job, match_result)\n",
    "print(\"\\n📩 Generated Cold Email:\\n\")\n",
    "print(cold_email)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13ebe6a-c53c-498c-83db-83d457cf75cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
